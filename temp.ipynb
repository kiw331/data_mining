{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://dacon.io/competitions/official/236176/overview/description',\n",
       " 'https://dacon.io/competitions/official/236170/overview/description']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "open_comp = []\n",
    "\n",
    "listpage_url = 'https://dacon.io/competitions'\n",
    "    \n",
    "# URL을 열고 해당 페이지 HTML 파싱\n",
    "html = urllib.request.urlopen(listpage_url)\n",
    "daconcomp = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# a태그 중에서 class 속성값이 \"clearfix\" 모두 찾기 (상위 페이지에 있는 모든 대회)\n",
    "all_comp = daconcomp.find_all('a', attrs={'class': 'clearfix'})\n",
    "\n",
    "# 상위 페이지의 모든 대회중 진행 중인 대회의 url크롤링\n",
    "for comp in all_comp:\n",
    "        \n",
    "    # 진행 중인 대회는 class속성값이 'dday'인 태그의 텍스트가 \"참가신청중\"이라고 표시됨\n",
    "    if comp.find('div', class_='dday').text.strip() == '참가신청중':\n",
    "    \n",
    "        #해당하는 대회의 url을 open_comp리스트에 저장\n",
    "        open_comp.append('https://dacon.io' + comp.get('href') + 'description')\n",
    "        \n",
    "open_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  참가신청중\n",
      "                </div>\n",
      "참가신청중\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  참가신청중\n",
      "                </div>\n",
      "참가신청중\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"non participating\" data-v-49aed458=\"\" src=\"/img/non-participating.jpg\"/>  마감\n",
      "                </div>\n",
      "마감\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n",
      "<div class=\"dday\" data-v-49aed458=\"\"><img alt=\"participating\" data-v-49aed458=\"\" src=\"/img/participating.jpg\"/>  연습\n",
      "                </div>\n",
      "연습\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "open_comp = []\n",
    "\n",
    "listpage_url = 'https://dacon.io/competitions'\n",
    "    \n",
    "# URL을 열고 해당 페이지 HTML 파싱\n",
    "html = urllib.request.urlopen(listpage_url)\n",
    "daconcomp = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# a태그 중에서 class 속성값이 \"clearfix\" 모두 찾기 (상위 페이지에 있는 모든 대회)\n",
    "all_comp = daconcomp.find_all('div', attrs={'class': 'dday'})\n",
    "\n",
    "\n",
    "for c in all_comp:\n",
    "    \n",
    "    text = c.get_text(strip=True)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진행 중인 대회 페이지의 url을 파싱\n",
    "def get_competition_url(open_comp):\n",
    "\n",
    "    listpage_url = 'https://dacon.io/competitions'\n",
    "    \n",
    "    # URL을 열고 해당 페이지 HTML 파싱\n",
    "    html = urllib.request.urlopen(listpage_url)\n",
    "    daconcomp = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # a태그 중에서 class 속성값이 \"clearfix\" 모두 찾기 (상위 페이지에 있는 모든 대회)\n",
    "    all_comp = daconcomp.find_all('a', attrs={'class': 'clearfix'})\n",
    "\n",
    "    # 상위 페이지의 모든 대회중 진행 중인 대회의 url크롤링\n",
    "    for comp in all_comp:\n",
    "        \n",
    "        # 진행 중인 대회는 class속성값이 'dday'인 태그의 텍스트가 \"참가신청중\"이라고 표시됨\n",
    "        if comp.find('div', class_='dday').text.strip() == '참가신청중':\n",
    "    \n",
    "            #해당하는 대회의 url을 open_comp리스트에 저장\n",
    "            open_comp.append('https://dacon.io' + comp.get('href') + 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진행 중인 대회 정보 파싱\n",
    "def get_competition_information(open_comp, result):\n",
    "    \n",
    "    for comp in open_comp:\n",
    "        \n",
    "        # URL을 열고 해당 페이지 HTML 파싱\n",
    "        html = urllib.request.urlopen(comp)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        #대회명\n",
    "        name = soup.title.string \n",
    "        \n",
    "        #분야\n",
    "        field = soup.h2.string.replace(\"\\n\", \"\")\n",
    "        \n",
    "        #현재 참가자\n",
    "        participants = soup.find('li', class_='d-inline text-body-2').get_text(strip=True).replace(\"\\n\", \"\")\n",
    "        index = participants.find('명')\n",
    "        participants = participants[:index+1] #~명까지 나오도록 전처리\n",
    "        \n",
    "        #상금\n",
    "        reward = soup.find('li', attrs={'class': \"text-body-2\"}).get_text(strip=True).replace(\"상금 :\", \"\").replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "        \n",
    "        result.append([name, field, participants, reward])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622명\n",
      "840명\n"
     ]
    }
   ],
   "source": [
    "for comp in open_comp:\n",
    "        \n",
    "    # URL을 열고 해당 페이지 HTML 파싱\n",
    "    html = urllib.request.urlopen(comp)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "    #name = soup.title.string #대회명\n",
    "    \n",
    "    reward = soup.find('li', attrs={'class': \"text-body-2\"}).get_text(strip=True).replace(\"상금 :\", \"\").replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "\n",
    "    #reward = soup.find('li', class_='text-body-2').get_text(strip=True)\n",
    "\n",
    "    #분야\n",
    "    field = soup.h2.string.replace(\"|\",\",\")\n",
    "        \n",
    "    #현재 참가자    \n",
    "    participants = soup.find('li', class_='d-inline text-body-2').get_text(strip=True)\n",
    "    index = participants.find('명')\n",
    "    participants = participants[:index+1] #~명까지 나오도록 전처리\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # 진행 중인 대회 url과 최종 결과를 저장한 리스트\n",
    "    open_comp, result = [], []\n",
    "    \n",
    "    # 진행 중인 대회 페이지가 있는 리스트 크롤링\n",
    "    get_competition_url(open_comp)\n",
    "    \n",
    "    # 진행 대회 정보: 대회명, 분야, 진행기간, 상금 크롤링\n",
    "    get_competition_information(open_comp,result)\n",
    "    \n",
    "    # pandas로 테이블 형태의 데이터프레임 생성\n",
    "    dacon_tbl = pd.DataFrame(result, columns = ('name', 'field', 'participants','reward'))\n",
    "    \n",
    "    # 한글출력을 위해 인코딩 cp949, 쓰기모드, 첫번째 열을 인덱스가 됨\n",
    "    dacon_tbl.to_csv('res/dacon1.csv', encoding = 'cp949', mode = 'w', index = True)\n",
    "    del result[:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
